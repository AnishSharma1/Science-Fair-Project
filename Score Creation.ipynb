{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrMDWj9g+WJkCqggwocS10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnishSharma1/Science-Fair-Project/blob/main/Untitled34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfoiItcdJaNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd7fc97c-ca08-4ba3-b3ff-c0e43ec98bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing packages...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úì Complete!\n",
            "======================================================================\n",
            "INTEGRATED MULTI-OMIC MOLECULAR MIMICRY PIPELINE\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PART 1: STRUCTURAL DATA INTEGRATION\n",
            "======================================================================\n",
            "\n",
            "üìÅ Upload TCR-matched predictions CSV:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b207718-d12f-4fd8-a47e-690becb6db61\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8b207718-d12f-4fd8-a47e-690becb6db61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving top_experimental_candidates (2).csv to top_experimental_candidates (2).csv\n",
            "‚úì Loaded 20 TCR-matched predictions\n",
            "\n",
            "üìÅ Upload PDB similarity/cross-reactivity CSV:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-049d8e04-0925-404c-8251-596a981595ec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-049d8e04-0925-404c-8251-596a981595ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving enhanced_cross_reactivity_analysis.csv to enhanced_cross_reactivity_analysis.csv\n",
            "‚úì Loaded 400 PDB similarity scores\n",
            "\n",
            "======================================================================\n",
            "PART 2: UNIFIED MOLECULAR MIMICRY SCORE CALCULATION\n",
            "======================================================================\n",
            "\n",
            "üîó Merging TCR and PDB datasets...\n",
            "‚ö† Column name mismatch - using all data separately\n",
            "\n",
            "======================================================================\n",
            "PART 3: BULK RNA-SEQ DATA INTEGRATION\n",
            "======================================================================\n",
            "\n",
            "üìÅ Upload bulk RNA-seq count matrix (CSV):\n",
            "   Format: Rows=genes, Columns=samples\n",
            "   First column should be gene names/IDs\n",
            "Do you have RNA-seq data to upload? (yes/no): no\n",
            "\n",
            "======================================================================\n",
            "PART 4: CLINICAL METADATA INTEGRATION\n",
            "======================================================================\n",
            "\n",
            "üìÅ Upload clinical metadata (CSV):\n",
            "   Should include: Sample_ID, Disease_Status, Age, Sex, etc.\n",
            "Do you have clinical data to upload? (yes/no): no\n",
            "\n",
            "======================================================================\n",
            "PART 5: MULTI-OMIC INTEGRATION & CORRELATION ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PART 6: COMPREHENSIVE MULTI-OMIC VISUALIZATIONS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PART 8: GENERATING COMPREHENSIVE REPORTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "‚úÖ ANALYSIS COMPLETE - FINAL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "INTERPRETATION GUIDE\n",
            "======================================================================\n",
            "\n",
            "üìå UNIFIED MIMICRY SCORE (0-100):\n",
            "   ‚Ä¢ Combines TCR binding energetics + peptide similarity + binding energy\n",
            "   ‚Ä¢ >70 = CRITICAL: Strong molecular mimicry, highest autoimmune risk\n",
            "   ‚Ä¢ 50-70 = HIGH: Significant cross-reactivity potential\n",
            "   ‚Ä¢ 30-50 = MODERATE: Some structural/functional similarity\n",
            "   ‚Ä¢ <30 = LOW: Minimal mimicry concern\n",
            "\n",
            "üî¨ COMPONENTS:\n",
            "   ‚Ä¢ TCR Component: How similarly TCR recognizes both peptides\n",
            "   ‚Ä¢ Peptide Component: Structural/sequence similarity\n",
            "   ‚Ä¢ Energy Component: Binding energy similarity\n",
            "   ‚Ä¢ Quality Weight: AlphaFold confidence (higher = more reliable)\n",
            "\n",
            "üéØ EXPERIMENTAL PRIORITIES:\n",
            "   1. Test top \"Critical\" pairs first\n",
            "   2. Validate with in vitro T-cell assays\n",
            "   3. Check patient samples for cross-reactive T-cells\n",
            "   4. Correlate with disease severity/progression\n",
            "\n",
            "üìÅ OUTPUT FILES:\n",
            "   ‚Ä¢ unified_mimicry_scores.csv - Complete integrated dataset\n",
            "   ‚Ä¢ top_mimicry_candidates.csv - Top 20 for experimental validation\n",
            "   ‚Ä¢ mimicry_component_breakdown.csv - Component analysis by risk class\n",
            "\n",
            "\n",
            "‚úÖ Pipeline complete! Review visualizations and exported files above.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Integrated Multi-Omic Molecular Mimicry Analysis Pipeline\n",
        "===========================================================\n",
        "Combines:\n",
        "1. TCR binding energetics (from enhanced analyzer)\n",
        "2. Peptide sequence/structure similarity (from PDB analyzer)\n",
        "3. Bulk RNA-seq data (gene expression)\n",
        "4. Clinical metadata (patient outcomes)\n",
        "\n",
        "Creates unified mimicry score and multi-omic integration\n",
        "\"\"\"\n",
        "\n",
        "# Installation\n",
        "print(\"Installing packages...\")\n",
        "!pip install biopython pandas matplotlib seaborn scipy scikit-learn umap-learn adjustText -q\n",
        "print(\"‚úì Complete!\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.cluster import hierarchy\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"INTEGRATED MULTI-OMIC MOLECULAR MIMICRY PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: LOAD AND INTEGRATE STRUCTURAL DATA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 1: STRUCTURAL DATA INTEGRATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìÅ Upload TCR-matched predictions CSV:\")\n",
        "tcr_file = files.upload()\n",
        "tcr_filename = list(tcr_file.keys())[0]\n",
        "tcr_df = pd.read_csv(tcr_filename)\n",
        "print(f\"‚úì Loaded {len(tcr_df)} TCR-matched predictions\")\n",
        "\n",
        "print(\"\\nüìÅ Upload PDB similarity/cross-reactivity CSV:\")\n",
        "pdb_file = files.upload()\n",
        "pdb_filename = list(pdb_file.keys())[0]\n",
        "pdb_df = pd.read_csv(pdb_filename)\n",
        "print(f\"‚úì Loaded {len(pdb_df)} PDB similarity scores\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: CREATE UNIFIED MIMICRY SCORE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 2: UNIFIED MOLECULAR MIMICRY SCORE CALCULATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def create_unified_mimicry_score(tcr_df, pdb_df):\n",
        "    \"\"\"\n",
        "    Combine TCR binding energetics with peptide similarity\n",
        "\n",
        "    TCR component: How well TCR recognizes both peptides\n",
        "    Peptide component: How similar the peptides are (sequence + structure)\n",
        "\n",
        "    Final score = weighted combination reflecting TRUE mimicry risk\n",
        "    \"\"\"\n",
        "\n",
        "    # Merge datasets on EBV and Myelin file identifiers\n",
        "    print(\"\\nüîó Merging TCR and PDB datasets...\")\n",
        "\n",
        "    # Normalize column names\n",
        "    tcr_df_norm = tcr_df.copy()\n",
        "    pdb_df_norm = pdb_df.copy()\n",
        "\n",
        "    # Try different merge strategies\n",
        "    # Strategy 1: Direct merge on filenames\n",
        "    if 'EBV_File' in tcr_df_norm.columns and 'EBV' in pdb_df_norm.columns:\n",
        "        # Clean filenames for matching\n",
        "        tcr_df_norm['EBV_clean'] = tcr_df_norm['EBV_File'].str.replace('.pdb', '').str.replace(' (1)', '').str.replace(' (2)', '')\n",
        "        tcr_df_norm['Myelin_clean'] = tcr_df_norm['Myelin_File'].str.replace('.pdb', '').str.replace(' (1)', '').str.replace(' (2)', '')\n",
        "\n",
        "        pdb_df_norm['EBV_clean'] = pdb_df_norm['EBV'].str.replace('.pdb', '').str.replace(' (1)', '').str.replace(' (2)', '')\n",
        "        pdb_df_norm['Myelin_clean'] = pdb_df_norm['Myelin'].str.replace('.pdb', '').str.replace(' (1)', '').str.replace(' (2)', '')\n",
        "\n",
        "        # Merge\n",
        "        merged_df = pd.merge(\n",
        "            tcr_df_norm,\n",
        "            pdb_df_norm,\n",
        "            left_on=['EBV_clean', 'Myelin_clean'],\n",
        "            right_on=['EBV_clean', 'Myelin_clean'],\n",
        "            how='inner',\n",
        "            suffixes=('_tcr', '_pdb')\n",
        "        )\n",
        "\n",
        "        print(f\"‚úì Merged {len(merged_df)} matching pairs\")\n",
        "    else:\n",
        "        print(\"‚ö† Column name mismatch - using all data separately\")\n",
        "        merged_df = None\n",
        "\n",
        "    if merged_df is not None and len(merged_df) > 0:\n",
        "        # Calculate unified mimicry score\n",
        "        print(\"\\nüßÆ Calculating Unified Molecular Mimicry Score...\")\n",
        "\n",
        "        # Component 1: TCR Recognition Similarity (0-100)\n",
        "        # High score = TCR binds both peptides similarly well\n",
        "        if 'TCR_Matched_Score' in merged_df.columns:\n",
        "            tcr_component = merged_df['TCR_Matched_Score']\n",
        "        elif 'Total_TCR_Energy' in merged_df.columns:\n",
        "            # Normalize energy to 0-100 scale\n",
        "            tcr_component = 100 - MinMaxScaler(feature_range=(0, 100)).fit_transform(\n",
        "                merged_df[['Total_TCR_Energy']].abs()\n",
        "            ).flatten()\n",
        "        else:\n",
        "            tcr_component = 50  # Default if no TCR data\n",
        "\n",
        "        # Component 2: Peptide Similarity (0-100)\n",
        "        # High score = peptides are structurally/sequentially similar\n",
        "        if 'Cross-Reactivity Score' in merged_df.columns:\n",
        "            peptide_component = merged_df['Cross-Reactivity Score']\n",
        "        elif 'Risk_Mean' in merged_df.columns:\n",
        "            peptide_component = merged_df['Risk_Mean']\n",
        "        else:\n",
        "            peptide_component = 50  # Default\n",
        "\n",
        "        # Component 3: Structural Quality Weight\n",
        "        # Weight by AlphaFold confidence - only trust high-quality structures\n",
        "        if 'Myelin_pLDDT' in merged_df.columns and 'EBV_pLDDT' in merged_df.columns:\n",
        "            avg_plddt = (merged_df['Myelin_pLDDT'] + merged_df['EBV_pLDDT']) / 2\n",
        "            quality_weight = avg_plddt / 100\n",
        "        else:\n",
        "            quality_weight = 1.0\n",
        "\n",
        "        # Component 4: Binding Energy Similarity\n",
        "        if 'EBV_Binding_Energy' in merged_df.columns and 'Myelin_Binding_Energy' in merged_df.columns:\n",
        "            energy_diff = abs(merged_df['EBV_Binding_Energy'] - merged_df['Myelin_Binding_Energy'])\n",
        "            max_energy = merged_df[['EBV_Binding_Energy', 'Myelin_Binding_Energy']].abs().max(axis=1)\n",
        "            energy_similarity = 100 * (1 - energy_diff / max_energy)\n",
        "        else:\n",
        "            energy_similarity = 50\n",
        "\n",
        "        # UNIFIED MIMICRY SCORE FORMULA\n",
        "        # High score = Strong molecular mimicry (dangerous!)\n",
        "        merged_df['Unified_Mimicry_Score'] = (\n",
        "            tcr_component * 0.35 +           # TCR recognition\n",
        "            peptide_component * 0.35 +       # Peptide similarity\n",
        "            energy_similarity * 0.30         # Energy similarity\n",
        "        ) * quality_weight\n",
        "\n",
        "        # Component scores for interpretation\n",
        "        merged_df['TCR_Component'] = tcr_component\n",
        "        merged_df['Peptide_Component'] = peptide_component\n",
        "        merged_df['Energy_Component'] = energy_similarity\n",
        "        merged_df['Quality_Weight'] = quality_weight\n",
        "\n",
        "        # Classification\n",
        "        merged_df['Mimicry_Class'] = pd.cut(\n",
        "            merged_df['Unified_Mimicry_Score'],\n",
        "            bins=[0, 30, 50, 70, 100],\n",
        "            labels=['Low', 'Moderate', 'High', 'Critical']\n",
        "        )\n",
        "\n",
        "        print(f\"\\nüìä Mimicry Score Distribution:\")\n",
        "        print(f\"   Mean: {merged_df['Unified_Mimicry_Score'].mean():.1f}\")\n",
        "        print(f\"   Median: {merged_df['Unified_Mimicry_Score'].median():.1f}\")\n",
        "        print(f\"   Range: {merged_df['Unified_Mimicry_Score'].min():.1f} - {merged_df['Unified_Mimicry_Score'].max():.1f}\")\n",
        "        print(f\"\\n   Critical (>70): {(merged_df['Unified_Mimicry_Score'] > 70).sum()}\")\n",
        "        print(f\"   High (50-70): {((merged_df['Unified_Mimicry_Score'] > 50) & (merged_df['Unified_Mimicry_Score'] <= 70)).sum()}\")\n",
        "        print(f\"   Moderate (30-50): {((merged_df['Unified_Mimicry_Score'] > 30) & (merged_df['Unified_Mimicry_Score'] <= 50)).sum()}\")\n",
        "        print(f\"   Low (<30): {(merged_df['Unified_Mimicry_Score'] <= 30).sum()}\")\n",
        "\n",
        "        return merged_df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "integrated_df = create_unified_mimicry_score(tcr_df, pdb_df)\n",
        "\n",
        "if integrated_df is not None:\n",
        "    # Export integrated scores\n",
        "    integrated_df.to_csv('unified_mimicry_scores.csv', index=False)\n",
        "    print(\"\\n‚úì unified_mimicry_scores.csv\")\n",
        "    files.download('unified_mimicry_scores.csv')\n",
        "\n",
        "# ============================================================================\n",
        "# PART 3: BULK RNA-SEQ INTEGRATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 3: BULK RNA-SEQ DATA INTEGRATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìÅ Upload bulk RNA-seq count matrix (CSV):\")\n",
        "print(\"   Format: Rows=genes, Columns=samples\")\n",
        "print(\"   First column should be gene names/IDs\")\n",
        "rnaseq_upload = input(\"Do you have RNA-seq data to upload? (yes/no): \")\n",
        "\n",
        "rnaseq_df = None\n",
        "if rnaseq_upload.lower() == 'yes':\n",
        "    rnaseq_file = files.upload()\n",
        "    rnaseq_filename = list(rnaseq_file.keys())[0]\n",
        "    rnaseq_df = pd.read_csv(rnaseq_filename, index_col=0)\n",
        "    print(f\"‚úì Loaded expression data: {rnaseq_df.shape[0]} genes √ó {rnaseq_df.shape[1]} samples\")\n",
        "\n",
        "    # Basic QC and normalization\n",
        "    print(\"\\nüî¨ RNA-seq preprocessing:\")\n",
        "\n",
        "    # Remove low-expression genes\n",
        "    min_expression = 10\n",
        "    expressed_genes = (rnaseq_df.sum(axis=1) > min_expression)\n",
        "    rnaseq_df = rnaseq_df[expressed_genes]\n",
        "    print(f\"   ‚Ä¢ Filtered to {len(rnaseq_df)} expressed genes (sum > {min_expression})\")\n",
        "\n",
        "    # Log2(CPM + 1) normalization\n",
        "    library_sizes = rnaseq_df.sum(axis=0)\n",
        "    cpm = rnaseq_df.div(library_sizes, axis=1) * 1e6\n",
        "    rnaseq_norm = np.log2(cpm + 1)\n",
        "    print(f\"   ‚Ä¢ Normalized: log2(CPM + 1)\")\n",
        "\n",
        "    # Identify immune/myelin-related genes\n",
        "    immune_genes = ['CD4', 'CD8A', 'CD8B', 'IFNG', 'TNF', 'IL2', 'IL10', 'IL17A',\n",
        "                    'FOXP3', 'GZMB', 'PRF1', 'CXCR3', 'CCR5', 'TBX21', 'GATA3']\n",
        "    myelin_genes = ['MBP', 'PLP1', 'MOG', 'MAG', 'CNP', 'MOBP']\n",
        "    ebv_response_genes = ['EBNA1', 'LMP1', 'LMP2A', 'IRF4', 'EBI3']\n",
        "\n",
        "    genes_of_interest = immune_genes + myelin_genes + ebv_response_genes\n",
        "    present_genes = [g for g in genes_of_interest if g in rnaseq_norm.index]\n",
        "\n",
        "    print(f\"\\n   üìã Key genes detected: {len(present_genes)}/{len(genes_of_interest)}\")\n",
        "    print(f\"      {', '.join(present_genes[:10])}...\")\n",
        "\n",
        "    # Calculate gene signatures\n",
        "    if len(present_genes) > 0:\n",
        "        gene_signatures = pd.DataFrame(index=rnaseq_norm.columns)\n",
        "\n",
        "        immune_present = [g for g in immune_genes if g in rnaseq_norm.index]\n",
        "        if immune_present:\n",
        "            gene_signatures['Immune_Score'] = rnaseq_norm.loc[immune_present].mean()\n",
        "\n",
        "        myelin_present = [g for g in myelin_genes if g in rnaseq_norm.index]\n",
        "        if myelin_present:\n",
        "            gene_signatures['Myelin_Score'] = rnaseq_norm.loc[myelin_present].mean()\n",
        "\n",
        "        ebv_present = [g for g in ebv_response_genes if g in rnaseq_norm.index]\n",
        "        if ebv_present:\n",
        "            gene_signatures['EBV_Response_Score'] = rnaseq_norm.loc[ebv_present].mean()\n",
        "\n",
        "        print(\"\\n   ‚úì Calculated gene signatures\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 4: CLINICAL METADATA INTEGRATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 4: CLINICAL METADATA INTEGRATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìÅ Upload clinical metadata (CSV):\")\n",
        "print(\"   Should include: Sample_ID, Disease_Status, Age, Sex, etc.\")\n",
        "clinical_upload = input(\"Do you have clinical data to upload? (yes/no): \")\n",
        "\n",
        "clinical_df = None\n",
        "if clinical_upload.lower() == 'yes':\n",
        "    clinical_file = files.upload()\n",
        "    clinical_filename = list(clinical_file.keys())[0]\n",
        "    clinical_df = pd.read_csv(clinical_filename)\n",
        "    print(f\"‚úì Loaded clinical data: {len(clinical_df)} samples\")\n",
        "    print(f\"   Columns: {', '.join(clinical_df.columns.tolist())}\")\n",
        "\n",
        "    # Display basic statistics\n",
        "    if 'Disease_Status' in clinical_df.columns:\n",
        "        print(f\"\\n   Disease distribution:\")\n",
        "        print(clinical_df['Disease_Status'].value_counts().to_string())\n",
        "\n",
        "# ============================================================================\n",
        "# PART 5: MULTI-OMIC INTEGRATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 5: MULTI-OMIC INTEGRATION & CORRELATION ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if rnaseq_df is not None and clinical_df is not None and integrated_df is not None:\n",
        "    print(\"\\nüîó Integrating structural, transcriptomic, and clinical data...\")\n",
        "\n",
        "    # Create integrated analysis\n",
        "    # Link peptide pairs to patient samples based on matching criteria\n",
        "\n",
        "    # For demonstration, we'll create correlation analyses\n",
        "    multi_omic_results = []\n",
        "\n",
        "    # Check if we can link samples\n",
        "    if 'Sample_ID' in clinical_df.columns and 'Sample_ID' in gene_signatures.index:\n",
        "        # Merge gene signatures with clinical data\n",
        "        integrated_clinical = pd.merge(\n",
        "            clinical_df,\n",
        "            gene_signatures,\n",
        "            left_on='Sample_ID',\n",
        "            right_index=True,\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "        print(f\"‚úì Integrated {len(integrated_clinical)} samples with both clinical and expression data\")\n",
        "\n",
        "        # Analyze relationships\n",
        "        if 'Disease_Status' in integrated_clinical.columns:\n",
        "            print(\"\\nüìä Gene Signature by Disease Status:\")\n",
        "            for col in gene_signatures.columns:\n",
        "                if col in integrated_clinical.columns:\n",
        "                    print(f\"\\n   {col}:\")\n",
        "                    grouped = integrated_clinical.groupby('Disease_Status')[col].agg(['mean', 'std', 'count'])\n",
        "                    print(grouped.to_string())\n",
        "\n",
        "                    # Statistical test\n",
        "                    groups = integrated_clinical.groupby('Disease_Status')[col].apply(list)\n",
        "                    if len(groups) == 2:\n",
        "                        stat, pval = stats.ttest_ind(groups.iloc[0], groups.iloc[1])\n",
        "                        print(f\"   t-test p-value: {pval:.4e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 6: COMPREHENSIVE VISUALIZATIONS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 6: COMPREHENSIVE MULTI-OMIC VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if integrated_df is not None:\n",
        "    fig = plt.figure(figsize=(20, 16))\n",
        "    gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "    # 1. Unified Mimicry Score Distribution\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax1.hist(integrated_df['Unified_Mimicry_Score'], bins=30,\n",
        "            color='purple', edgecolor='black', alpha=0.7)\n",
        "    ax1.axvline(70, color='red', linestyle='--', linewidth=2, label='Critical threshold')\n",
        "    ax1.axvline(50, color='orange', linestyle='--', linewidth=2, label='High threshold')\n",
        "    ax1.set_xlabel('Unified Mimicry Score', fontsize=11)\n",
        "    ax1.set_ylabel('Frequency', fontsize=11)\n",
        "    ax1.set_title('Unified Mimicry Score Distribution', fontsize=13, fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    # 2. Component Contribution\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    components = ['TCR_Component', 'Peptide_Component', 'Energy_Component']\n",
        "    component_means = [integrated_df[c].mean() for c in components]\n",
        "    colors_comp = ['orchid', 'lightcoral', 'lightblue']\n",
        "    bars = ax2.bar(range(3), component_means, color=colors_comp, edgecolor='black', linewidth=1.5)\n",
        "    ax2.set_xticks(range(3))\n",
        "    ax2.set_xticklabels(['TCR\\nRecognition', 'Peptide\\nSimilarity', 'Energy\\nSimilarity'], fontsize=10)\n",
        "    ax2.set_ylabel('Mean Score', fontsize=11)\n",
        "    ax2.set_title('Mimicry Score Components', fontsize=13, fontweight='bold')\n",
        "    ax2.set_ylim([0, 100])\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add values on bars\n",
        "    for i, (bar, val) in enumerate(zip(bars, component_means)):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2, val + 2, f'{val:.1f}',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # 3. TCR vs Peptide Components\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    scatter = ax3.scatter(integrated_df['TCR_Component'],\n",
        "                         integrated_df['Peptide_Component'],\n",
        "                         c=integrated_df['Unified_Mimicry_Score'],\n",
        "                         s=80, cmap='RdYlGn_r', alpha=0.6,\n",
        "                         edgecolors='black', linewidth=0.5)\n",
        "    ax3.plot([0, 100], [0, 100], 'k--', alpha=0.3, linewidth=1)\n",
        "    ax3.set_xlabel('TCR Recognition Score', fontsize=11)\n",
        "    ax3.set_ylabel('Peptide Similarity Score', fontsize=11)\n",
        "    ax3.set_title('Component Correlation', fontsize=13, fontweight='bold')\n",
        "    plt.colorbar(scatter, ax=ax3, label='Unified Score')\n",
        "    ax3.grid(alpha=0.3)\n",
        "\n",
        "    # 4. Top 10 mimicry pairs\n",
        "    ax4 = fig.add_subplot(gs[1, :])\n",
        "    top10 = integrated_df.nlargest(10, 'Unified_Mimicry_Score')\n",
        "    y_pos = np.arange(len(top10))\n",
        "\n",
        "    # Create color map based on classification\n",
        "    colors_risk = {'Critical': 'red', 'High': 'orange', 'Moderate': 'yellow', 'Low': 'green'}\n",
        "    bar_colors = [colors_risk.get(c, 'gray') for c in top10['Mimicry_Class']]\n",
        "\n",
        "    bars = ax4.barh(y_pos, top10['Unified_Mimicry_Score'],\n",
        "                    color=bar_colors, edgecolor='black', linewidth=1.5, alpha=0.8)\n",
        "    ax4.set_yticks(y_pos)\n",
        "\n",
        "    # Create labels\n",
        "    labels = []\n",
        "    for idx, row in top10.iterrows():\n",
        "        ebv_short = row.get('EBV_clean', row.get('EBV_File', 'Unknown'))[:25]\n",
        "        myelin_short = row.get('Myelin_clean', row.get('Myelin_File', 'Unknown'))[:25]\n",
        "        labels.append(f\"{ebv_short}\\n‚Üî {myelin_short}\")\n",
        "\n",
        "    ax4.set_yticklabels(labels, fontsize=8)\n",
        "    ax4.set_xlabel('Unified Mimicry Score', fontsize=11)\n",
        "    ax4.set_title('Top 10 Molecular Mimicry Candidates', fontsize=13, fontweight='bold')\n",
        "    ax4.invert_yaxis()\n",
        "    ax4.grid(axis='x', alpha=0.3)\n",
        "    ax4.axvline(70, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
        "    ax4.axvline(50, color='orange', linestyle='--', linewidth=1, alpha=0.5)\n",
        "\n",
        "    # Add score text\n",
        "    for i, (bar, score) in enumerate(zip(bars, top10['Unified_Mimicry_Score'])):\n",
        "        ax4.text(score + 1, bar.get_y() + bar.get_height()/2,\n",
        "                f'{score:.1f}', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "    # 5. Quality weight impact\n",
        "    ax5 = fig.add_subplot(gs[2, 0])\n",
        "    ax5.scatter(integrated_df['Quality_Weight'],\n",
        "               integrated_df['Unified_Mimicry_Score'],\n",
        "               c=integrated_df['Peptide_Component'],\n",
        "               s=60, cmap='viridis', alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "    ax5.set_xlabel('Quality Weight (Avg pLDDT)', fontsize=11)\n",
        "    ax5.set_ylabel('Unified Mimicry Score', fontsize=11)\n",
        "    ax5.set_title('Structure Quality Impact', fontsize=13, fontweight='bold')\n",
        "    ax5.grid(alpha=0.3)\n",
        "\n",
        "    # 6. Mimicry class distribution\n",
        "    ax6 = fig.add_subplot(gs[2, 1])\n",
        "    class_counts = integrated_df['Mimicry_Class'].value_counts()\n",
        "    colors_pie = ['green', 'yellow', 'orange', 'red']\n",
        "    wedges, texts, autotexts = ax6.pie(class_counts.values,\n",
        "                                        labels=class_counts.index,\n",
        "                                        colors=colors_pie,\n",
        "                                        autopct='%1.1f%%',\n",
        "                                        startangle=90,\n",
        "                                        explode=[0.05]*len(class_counts))\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "    ax6.set_title('Mimicry Risk Classification', fontsize=13, fontweight='bold')\n",
        "\n",
        "    # 7. Component correlation heatmap\n",
        "    ax7 = fig.add_subplot(gs[2, 2])\n",
        "    corr_data = integrated_df[['TCR_Component', 'Peptide_Component',\n",
        "                                'Energy_Component', 'Unified_Mimicry_Score']].corr()\n",
        "    sns.heatmap(corr_data, annot=True, fmt='.3f', cmap='coolwarm',\n",
        "               center=0, vmin=-1, vmax=1, ax=ax7,\n",
        "               square=True, linewidths=1, cbar_kws={'label': 'Correlation'})\n",
        "    ax7.set_title('Component Correlations', fontsize=13, fontweight='bold')\n",
        "\n",
        "    # 8. RNA-seq integration (if available)\n",
        "    if rnaseq_df is not None and 'gene_signatures' in locals():\n",
        "        ax8 = fig.add_subplot(gs[3, 0])\n",
        "\n",
        "        if 'Immune_Score' in gene_signatures.columns:\n",
        "            ax8.hist(gene_signatures['Immune_Score'], bins=20,\n",
        "                    color='steelblue', edgecolor='black', alpha=0.7)\n",
        "            ax8.set_xlabel('Immune Signature Score', fontsize=11)\n",
        "            ax8.set_ylabel('Frequency', fontsize=11)\n",
        "            ax8.set_title('Immune Gene Expression', fontsize=13, fontweight='bold')\n",
        "            ax8.grid(alpha=0.3)\n",
        "\n",
        "    # 9. Clinical correlation (if available)\n",
        "    if clinical_df is not None and 'integrated_clinical' in locals():\n",
        "        ax9 = fig.add_subplot(gs[3, 1])\n",
        "\n",
        "        if 'Disease_Status' in integrated_clinical.columns and 'Immune_Score' in integrated_clinical.columns:\n",
        "            disease_groups = integrated_clinical.groupby('Disease_Status')['Immune_Score'].apply(list)\n",
        "\n",
        "            bp = ax9.boxplot(disease_groups.values, labels=disease_groups.index,\n",
        "                           patch_artist=True)\n",
        "            for patch in bp['boxes']:\n",
        "                patch.set_facecolor('lightblue')\n",
        "            ax9.set_ylabel('Immune Score', fontsize=11)\n",
        "            ax9.set_title('Immune Score by Disease', fontsize=13, fontweight='bold')\n",
        "            ax9.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 10. Summary statistics table\n",
        "    ax10 = fig.add_subplot(gs[3, 2])\n",
        "    ax10.axis('off')\n",
        "\n",
        "    summary_data = [\n",
        "        ['Metric', 'Value'],\n",
        "        ['Total Pairs Analyzed', f\"{len(integrated_df)}\"],\n",
        "        ['Mean Mimicry Score', f\"{integrated_df['Unified_Mimicry_Score'].mean():.1f}\"],\n",
        "        ['Critical Risk Pairs', f\"{(integrated_df['Unified_Mimicry_Score'] > 70).sum()}\"],\n",
        "        ['High Risk Pairs', f\"{((integrated_df['Unified_Mimicry_Score'] > 50) & (integrated_df['Unified_Mimicry_Score'] <= 70)).sum()}\"],\n",
        "        ['Mean TCR Component', f\"{integrated_df['TCR_Component'].mean():.1f}\"],\n",
        "        ['Mean Peptide Component', f\"{integrated_df['Peptide_Component'].mean():.1f}\"],\n",
        "        ['Mean Quality Weight', f\"{integrated_df['Quality_Weight'].mean():.3f}\"],\n",
        "    ]\n",
        "\n",
        "    table = ax10.table(cellText=summary_data, cellLoc='left', loc='center',\n",
        "                      colWidths=[0.65, 0.35])\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 2.5)\n",
        "\n",
        "    for i in range(len(summary_data)):\n",
        "        if i == 0:\n",
        "            table[(i, 0)].set_facecolor('#40466e')\n",
        "            table[(i, 1)].set_facecolor('#40466e')\n",
        "            table[(i, 0)].set_text_props(weight='bold', color='white')\n",
        "            table[(i, 1)].set_text_props(weight='bold', color='white')\n",
        "        else:\n",
        "            table[(i, 0)].set_facecolor('#f0f0f0' if i % 2 == 0 else 'white')\n",
        "            table[(i, 1)].set_facecolor('#f0f0f0' if i % 2 == 0 else 'white')\n",
        "\n",
        "    ax10.set_title('Summary Statistics', fontsize=13, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.suptitle('Integrated Multi-Omic Molecular Mimicry Analysis',\n",
        "                fontsize=18, fontweight='bold', y=0.998)\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# PART 7: DIMENSIONAL REDUCTION FOR PATTERN DISCOVERY\n",
        "# ============================================================================\n",
        "if integrated_df is not None and len(integrated_df) > 10:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PART 7: DIMENSIONAL REDUCTION & PATTERN DISCOVERY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Prepare feature matrix\n",
        "    feature_cols = ['TCR_Component', 'Peptide_Component', 'Energy_Component']\n",
        "\n",
        "    # Add additional features if available\n",
        "    if 'EBV_Contacts' in integrated_df.columns:\n",
        "        feature_cols.extend(['EBV_Contacts', 'Myelin_Contacts'])\n",
        "    if 'EBV_HBonds' in integrated_df.columns:\n",
        "        feature_cols.extend(['EBV_HBonds', 'Myelin_HBonds'])\n",
        "\n",
        "    X = integrated_df[feature_cols].fillna(0).values\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    # t-SNE\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "    # UMAP\n",
        "    reducer = umap.UMAP(random_state=42)\n",
        "    X_umap = reducer.fit_transform(X_scaled)\n",
        "\n",
        "    # Visualization\n",
        "    fig2, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # PCA\n",
        "    scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1],\n",
        "                              c=integrated_df['Unified_Mimicry_Score'],\n",
        "                              cmap='RdYlGn_r', s=80, alpha=0.6,\n",
        "                              edgecolors='black', linewidth=0.5)\n",
        "    axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=11)\n",
        "    axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=11)\n",
        "    axes[0].set_title('PCA Projection', fontsize=13, fontweight='bold')\n",
        "    plt.colorbar(scatter1, ax=axes[0], label='Mimicry Score')\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # t-SNE\n",
        "    scatter2 = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1],\n",
        "                              c=integrated_df['Unified_Mimicry_Score'],\n",
        "                              cmap='RdYlGn_r', s=80, alpha=0.6,\n",
        "                              edgecolors='black', linewidth=0.5)\n",
        "    axes[1].set_xlabel('t-SNE 1', fontsize=11)\n",
        "    axes[1].set_ylabel('t-SNE 2', fontsize=11)\n",
        "    axes[1].set_title('t-SNE Projection', fontsize=13, fontweight='bold')\n",
        "    plt.colorbar(scatter2, ax=axes[1], label='Mimicry Score')\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    # UMAP\n",
        "    scatter3 = axes[2].scatter(X_umap[:, 0], X_umap[:, 1],\n",
        "                              c=integrated_df['Unified_Mimicry_Score'],\n",
        "                              cmap='RdYlGn_r', s=80, alpha=0.6,\n",
        "                              edgecolors='black', linewidth=0.5)\n",
        "    axes[2].set_xlabel('UMAP 1', fontsize=11)\n",
        "    axes[2].set_ylabel('UMAP 2', fontsize=11)\n",
        "    axes[2].set_title('UMAP Projection', fontsize=13, fontweight='bold')\n",
        "    plt.colorbar(scatter3, ax=axes[2], label='Mimicry Score')\n",
        "    axes[2].grid(alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Dimensional Reduction Analysis', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n‚úì PCA variance explained: {pca.explained_variance_ratio_[0]*100:.1f}% + {pca.explained_variance_ratio_[1]*100:.1f}% = {pca.explained_variance_ratio_[:2].sum()*100:.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 8: GENERATE COMPREHENSIVE REPORTS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART 8: GENERATING COMPREHENSIVE REPORTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if integrated_df is not None:\n",
        "    # Top candidates report\n",
        "    top_candidates = integrated_df.nlargest(20, 'Unified_Mimicry_Score')[[\n",
        "        'EBV_File', 'Myelin_File', 'Unified_Mimicry_Score',\n",
        "        'TCR_Component', 'Peptide_Component', 'Energy_Component',\n",
        "        'Mimicry_Class', 'Quality_Weight'\n",
        "    ]]\n",
        "\n",
        "    top_candidates.to_csv('top_mimicry_candidates.csv', index=False)\n",
        "    print(\"‚úì top_mimicry_candidates.csv\")\n",
        "    files.download('top_mimicry_candidates.csv')\n",
        "\n",
        "    # Component breakdown\n",
        "    component_analysis = integrated_df.groupby('Mimicry_Class').agg({\n",
        "        'Unified_Mimicry_Score': ['mean', 'std', 'count'],\n",
        "        'TCR_Component': 'mean',\n",
        "        'Peptide_Component': 'mean',\n",
        "        'Energy_Component': 'mean',\n",
        "        'Quality_Weight': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    component_analysis.to_csv('mimicry_component_breakdown.csv')\n",
        "    print(\"‚úì mimicry_component_breakdown.csv\")\n",
        "    files.download('mimicry_component_breakdown.csv')\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY AND INTERPRETATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ ANALYSIS COMPLETE - FINAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if integrated_df is not None:\n",
        "    print(f\"\\nüìä UNIFIED MIMICRY ANALYSIS:\")\n",
        "    print(f\"   ‚Ä¢ Analyzed {len(integrated_df)} peptide pairs\")\n",
        "    print(f\"   ‚Ä¢ Mean Unified Mimicry Score: {integrated_df['Unified_Mimicry_Score'].mean():.1f}\")\n",
        "    print(f\"   ‚Ä¢ Critical risk pairs (>70): {(integrated_df['Unified_Mimicry_Score'] > 70).sum()}\")\n",
        "    print(f\"   ‚Ä¢ High risk pairs (50-70): {((integrated_df['Unified_Mimicry_Score'] > 50) & (integrated_df['Unified_Mimicry_Score'] <= 70)).sum()}\")\n",
        "\n",
        "if rnaseq_df is not None:\n",
        "    print(f\"\\nüß¨ TRANSCRIPTOMIC DATA:\")\n",
        "    print(f\"   ‚Ä¢ {rnaseq_df.shape[0]} genes analyzed\")\n",
        "    print(f\"   ‚Ä¢ {rnaseq_df.shape[1]} samples profiled\")\n",
        "\n",
        "if clinical_df is not None:\n",
        "    print(f\"\\nüè• CLINICAL DATA:\")\n",
        "    print(f\"   ‚Ä¢ {len(clinical_df)} patients\")\n",
        "    if 'Disease_Status' in clinical_df.columns:\n",
        "        print(f\"   ‚Ä¢ Disease groups: {', '.join(clinical_df['Disease_Status'].unique())}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION GUIDE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "üìå UNIFIED MIMICRY SCORE (0-100):\n",
        "   ‚Ä¢ Combines TCR binding energetics + peptide similarity + binding energy\n",
        "   ‚Ä¢ >70 = CRITICAL: Strong molecular mimicry, highest autoimmune risk\n",
        "   ‚Ä¢ 50-70 = HIGH: Significant cross-reactivity potential\n",
        "   ‚Ä¢ 30-50 = MODERATE: Some structural/functional similarity\n",
        "   ‚Ä¢ <30 = LOW: Minimal mimicry concern\n",
        "\n",
        "üî¨ COMPONENTS:\n",
        "   ‚Ä¢ TCR Component: How similarly TCR recognizes both peptides\n",
        "   ‚Ä¢ Peptide Component: Structural/sequence similarity\n",
        "   ‚Ä¢ Energy Component: Binding energy similarity\n",
        "   ‚Ä¢ Quality Weight: AlphaFold confidence (higher = more reliable)\n",
        "\n",
        "üéØ EXPERIMENTAL PRIORITIES:\n",
        "   1. Test top \"Critical\" pairs first\n",
        "   2. Validate with in vitro T-cell assays\n",
        "   3. Check patient samples for cross-reactive T-cells\n",
        "   4. Correlate with disease severity/progression\n",
        "\n",
        "üìÅ OUTPUT FILES:\n",
        "   ‚Ä¢ unified_mimicry_scores.csv - Complete integrated dataset\n",
        "   ‚Ä¢ top_mimicry_candidates.csv - Top 20 for experimental validation\n",
        "   ‚Ä¢ mimicry_component_breakdown.csv - Component analysis by risk class\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n‚úÖ Pipeline complete! Review visualizations and exported files above.\")\n",
        "print(\"=\"*70)"
      ]
    }
  ]
}
